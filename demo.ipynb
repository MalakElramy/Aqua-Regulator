{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "Bad magic number for central directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Load the fine-tuned MobileNetV2 model\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMobileNetV2_fine_tuned_Marine_Life.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Define the class labels (you need to replace these with the actual labels from your model)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m class_labels \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClams\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorals\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrabs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDolphin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFish\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJelly Fish\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLobster\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNudibranchs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOctopus\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     17\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPenguin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPuffers\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSea Rays\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSea Urchins\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeahorse\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSharks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShrimp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSquid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     18\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTurtle_Tortoise\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhale\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# Modify this based on your dataset labels\u001b[39;00m\n",
      "File \u001b[1;32md:\\ISEF\\ISEF\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    186\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n",
      "File \u001b[1;32md:\\ISEF\\ISEF\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:367\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m     )\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\ISEF\\ISEF\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:440\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_load_model_from_fileobj\u001b[39m(fileobj, custom_objects, \u001b[38;5;28mcompile\u001b[39m, safe_mode):\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m zf:\n\u001b[0;32m    441\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m zf\u001b[38;5;241m.\u001b[39mopen(_CONFIG_FILENAME, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    442\u001b[0m             config_json \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\zipfile\\__init__.py:1349\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1349\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1350\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1351\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1352\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\zipfile\\__init__.py:1446\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1444\u001b[0m centdir \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(structCentralDir, centdir)\n\u001b[0;32m   1445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m centdir[_CD_SIGNATURE] \u001b[38;5;241m!=\u001b[39m stringCentralDir:\n\u001b[1;32m-> 1446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBad magic number for central directory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   1448\u001b[0m     \u001b[38;5;28mprint\u001b[39m(centdir)\n",
      "\u001b[1;31mBadZipFile\u001b[0m: Bad magic number for central directory"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io\n",
    "import cv2\n",
    "\n",
    "# Load the fine-tuned MobileNetV2 model\n",
    "model = tf.keras.models.load_model('MobileNetV2_fine_tuned_Marine_Life.keras')\n",
    "\n",
    "# Define the class labels (you need to replace these with the actual labels from your model)\n",
    "class_labels = [\"Clams\", \"Corals\", \"Crabs\", \"Dolphin\", \"Eel\", \"Fish\", \"Jelly Fish\", \"Lobster\", \"Nudibranchs\", \"Octopus\", \n",
    "                \"Otter\", \"Penguin\", \"Puffers\", \"Sea Rays\", \"Sea Urchins\", \"Seahorse\", \"Seal\", \"Sharks\", \"Shrimp\", \"Squid\", \n",
    "                \"Turtle_Tortoise\", \"Whale\"]  # Modify this based on your dataset labels\n",
    "\n",
    "# Function to preprocess the image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))  # Resize the image to 224x224 (MobileNetV2 input size)\n",
    "    img_array = image.img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)  # Preprocess for MobileNetV2\n",
    "    return img_array\n",
    "\n",
    "# Function to make prediction\n",
    "def make_prediction(img_array):\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)  # Get the index of the highest probability\n",
    "    confidence = predictions[0][predicted_class]  # Confidence score\n",
    "    return predicted_class[0], confidence\n",
    "\n",
    "# Function to handle the uploaded image\n",
    "def handle_uploaded_image(change):\n",
    "    # Get the uploaded file\n",
    "    file = upload_widget.value[0]  \n",
    "    image_data = file['content']   # Get the content of the uploaded file\n",
    "    image_path = io.BytesIO(image_data)  # Open image from bytes\n",
    "    \n",
    "    # Open and preprocess the image\n",
    "    img = Image.open(image_path)\n",
    "    img.show()  # Display the image\n",
    "    \n",
    "    # Preprocess the image for the model\n",
    "    img_array = preprocess_image(image_path)\n",
    "    \n",
    "    # Make the prediction\n",
    "    predicted_class, confidence = make_prediction(img_array)\n",
    "    \n",
    "    # Display the prediction result\n",
    "    print(f\"Predicted Class: {class_labels[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence * 100:.2f}%\")\n",
    "    \n",
    "    # Convert image to an array (for display)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')  # Hide axis\n",
    "    plt.show()\n",
    "\n",
    "# Create the file upload widget\n",
    "upload_widget = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
    "display(upload_widget)\n",
    "\n",
    "# Link the function to handle the uploaded image\n",
    "upload_widget.observe(handle_uploaded_image, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned MobileNetV2 model\n",
    "model = tf.keras.models.load_model('MobileNetV2_fine_tuned_Marine_Life.keras')\n",
    "\n",
    "# Define the class labels (you need to replace these with the actual labels from your model)\n",
    "class_labels = [\"Clams\", \"Corals\", \"Crabs\", \"Dolphin\", \"Eel\", \"Fish\", \"Jelly Fish\", \"Lobster\", \"Nudibranchs\", \"Octopus\", \n",
    "                \"Otter\", \"Penguin\", \"Puffers\", \"Sea Rays\", \"Sea Urchins\", \"Seahorse\", \"Seal\", \"Sharks\", \"Shrimp\", \"Squid\", \n",
    "                \"Turtle_Tortoise\", \"Whale\"]  # Modify this based on your dataset labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import Tk, filedialog\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "\n",
    "\n",
    "def upload_image():\n",
    "    root = Tk()\n",
    "    root.withdraw()  # Hide the Tkinter root window\n",
    "    file_path = filedialog.askopenfilename()  # Open file dialog to select image\n",
    "    return file_path\n",
    "\n",
    "# Function to preprocess the image for prediction\n",
    "def preprocess_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))  # Resize the image to 224x224 (MobileNetV2 input size)\n",
    "    img_array = image.img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)  # Preprocess for MobileNetV2\n",
    "    return img_array\n",
    "\n",
    "# Function to make prediction\n",
    "def make_prediction(img_array):\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)  # Get the index of the highest probability\n",
    "    confidence = predictions[0][predicted_class]  # Confidence score\n",
    "    return predicted_class[0], confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Create an upload widget\n",
    "upload_widget = widgets.FileUpload(accept=\"image/*\", multiple=False)\n",
    "display(upload_widget)\n",
    "\n",
    "# Function to handle the uploaded image\n",
    "def handle_uploaded_image(change):\n",
    "    file = upload_widget.value[0]  # Get the uploaded file\n",
    "    image_data = file['content']   # Get the content of the uploaded file\n",
    "    image = Image.open(io.BytesIO(image_data))  # Open image\n",
    "    image.show()  # Display the image\n",
    "    # You can now preprocess and predict the image as before\n",
    "\n",
    "# Link the function to the widget\n",
    "upload_widget.observe(handle_uploaded_image, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Upload the image\n",
    "image_path = upload_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess the image\n",
    "img_array = preprocess_image(image_path)\n",
    "\n",
    "# Make the prediction\n",
    "predicted_class, confidence = make_prediction(img_array)\n",
    "\n",
    "\n",
    "img = cv2.imread(image_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for displaying\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Hide axis\n",
    "plt.show()\n",
    "\n",
    "# Display the prediction result\n",
    "print(f\"Predicted Class: {class_labels[predicted_class]}\")\n",
    "print(f\"Confidence: {confidence * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import serial\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Load your fine-tuned MobileNetV2 model\n",
    "model = tf.keras.models.load_model('MobileNetV2_fine_tuned_Marine_Life.keras')\n",
    "\n",
    "# Define the class labels for your model\n",
    "class_labels = [\"Clams\", \"Corals\", \"Crabs\", \"Dolphin\", \"Eel\", \"Fish\", \"Jelly Fish\", \"Lobster\", \n",
    "                \"Nudibranchs\", \"Octopus\", \"Otter\", \"Penguin\", \"Puffers\", \"Sea Rays\", \"Sea Urchins\", \n",
    "                \"Seahorse\", \"Seal\", \"Sharks\", \"Shrimp\", \"Squid\", \"Turtle_Tortoise\", \"Whale\"]\n",
    "\n",
    "# Function to preprocess the image for prediction\n",
    "def preprocess_image(frame):\n",
    "    img = cv2.resize(frame, (224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "    return img_array\n",
    "\n",
    "# Function to make prediction\n",
    "def make_prediction(img_array):\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    confidence = predictions[0][predicted_class]\n",
    "    return predicted_class, confidence\n",
    "\n",
    "# Open the webcam (use 0 for default webcam)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set up serial communication (ensure the correct port is used)\n",
    "arduino = serial.Serial('COM3', 9600)  # Change 'COM3' to your Arduino's port\n",
    "arduino.flush()  # Clear any data in the buffer\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "else:\n",
    "    try:\n",
    "        while True:\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                print(\"Failed to grab frame.\")\n",
    "                break\n",
    "\n",
    "            # Preprocess the frame for prediction\n",
    "            img_array = preprocess_image(frame)\n",
    "\n",
    "            # Make the prediction\n",
    "            predicted_class, confidence = make_prediction(img_array)\n",
    "\n",
    "            # Error handling for prediction out of range\n",
    "            if 0 <= predicted_class < len(class_labels):\n",
    "                label = f\"{class_labels[predicted_class]}: {confidence * 100:.2f}%\"\n",
    "            else:\n",
    "                label = \"Prediction out of range\"\n",
    "\n",
    "            # Send data to Arduino (animal name and confidence)\n",
    "            arduino.write(f\"{class_labels[predicted_class]},{confidence}\\n\".encode())  # Send the detected label and confidence\n",
    "\n",
    "            cv2.putText(frame, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Convert the frame (BGR to RGB) for displaying in Jupyter\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(frame_rgb)\n",
    "            display(img)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stream stopped.\")\n",
    "\n",
    "    finally:\n",
    "        # Release the webcam when finished\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        arduino.close()  # Close the serial connection\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
